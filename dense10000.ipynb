{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 1: GeForce GTX TITAN X (CNMeM is disabled, cuDNN not available)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Import io functions\n",
    "from io_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the gammas and pi0s as nparrays of 20x20x25 event arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the datasets for the first time\n",
    "#signal = get_dataset('/data/vlimant/LCD/Gamma100GeV')\n",
    "#bkg = get_dataset('/data/vlimant/LCD/Pi0100GeV')\n",
    "\n",
    "# Save the datasets for faster future loading\n",
    "#save_dataset(\"/data/vlimant/LCD/Gamma100GeV\", signal)\n",
    "#save_dataset(\"/data/vlimant/LCD/Pi0100GeV\", bkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "signal = load_dataset(\"/data/vlimant/LCD/Gamma100GeV\")\n",
    "bkg = load_dataset(\"/data/vlimant/LCD/Pi0100GeV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1 is signal, 0 is background\n",
    "X = np.concatenate( (signal, bkg), axis=0 )\n",
    "Y = np.zeros( (len(X)) )\n",
    "Y[:len(signal)] = 1\n",
    "p = np.random.permutation(len(X))\n",
    "X = X[p]\n",
    "Y = Y[p]\n",
    "X = X.reshape((X.shape[0], 10000))\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct and compile a network\n",
    "model = Sequential()\n",
    "model.add(Dense(10000, input_dim=10000, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10000, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the network\n",
    "my_fit = model.fit(train_data, train_labels, nb_epoch=100, batch_size=100, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the test signal and background to make the histogram\n",
    "test_signal = test_data[np.where(test_labels==1)]\n",
    "test_bkg    = test_data[np.where(test_labels==0)]\n",
    "\n",
    "# Calculate the probabilities for the test sets\n",
    "p_signal    = model.predict(test_signal)\n",
    "p_bkg       = model.predict(test_bkg)\n",
    "\n",
    "# Draw classification histogram\n",
    "plt.hist(p_signal, 50, normed=1, facecolor='blue', alpha=0.4, label='gamma')\n",
    "plt.hist(p_bkg , 50, normed=1, facecolor='red' , alpha=0.4, label='pi0')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Probability')\n",
    "plt.title(r'$\\mathrm{Histogram\\ of\\ IQ:}\\ \\mu=100,\\ \\sigma=15$')\n",
    "plt.yscale('log')\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get classification predictions\n",
    "predictions = model.predict(test_data)\n",
    "\n",
    "# Draw the ROC curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, _ = roc_curve(test_labels, predictions)\n",
    "plt.xlim([.0, 1.04])\n",
    "plt.ylim([.0, 1.04])\n",
    "#plt.xlabel('Prediction')\n",
    "#plt.ylabel('Probability')\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.plot( tpr, 1-fpr )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Draw the fit history\n",
    "#plt.xlim(left=0)\n",
    "plt.ylim(bottom=0)\n",
    "plt.xlabel('Loss')\n",
    "plt.ylabel('Epoch')\n",
    "plt.title('Training Error by Epoch')\n",
    "plt.plot(my_fit.history['loss'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
